{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"RTM \u00b6 The Greater Vancouver Regional Travel Model (RTM) is a four-step travel demand model developed and maintained by the South Coast British Columbia Transportation Authority (also known as TransLink). It provides long-range forecast and informs major transportation investments and policy decisions for the Metro Vancouver Regional District (MVRD). Introduction \u00b6 The RTM is a package of software that extends the functionalities of INRO EMME to model travel behaviors in the MVRD. The RTM software, written in python for EMME, handles all aspect of the four-step travel demand model: trip generation, trip distribution, mode choice, and network assignment. The RTM takes advantage of EMME's network editor and network assignment capability to capture user equilibrium network conditions. The latest version of the model is based on: 2011 Trip Diary and Screenline Survey ; Metro Vancouver Regional Growth Projections; and BC Provincial Digital Road Atlas . Get in touch \u00b6 If you require access to the RTM or would like to stay in touch, see Contributing .","title":"RTM"},{"location":"#rtm","text":"The Greater Vancouver Regional Travel Model (RTM) is a four-step travel demand model developed and maintained by the South Coast British Columbia Transportation Authority (also known as TransLink). It provides long-range forecast and informs major transportation investments and policy decisions for the Metro Vancouver Regional District (MVRD).","title":"RTM"},{"location":"#introduction","text":"The RTM is a package of software that extends the functionalities of INRO EMME to model travel behaviors in the MVRD. The RTM software, written in python for EMME, handles all aspect of the four-step travel demand model: trip generation, trip distribution, mode choice, and network assignment. The RTM takes advantage of EMME's network editor and network assignment capability to capture user equilibrium network conditions. The latest version of the model is based on: 2011 Trip Diary and Screenline Survey ; Metro Vancouver Regional Growth Projections; and BC Provincial Digital Road Atlas .","title":"Introduction"},{"location":"#get-in-touch","text":"If you require access to the RTM or would like to stay in touch, see Contributing .","title":"Get in touch"},{"location":"data_analysis/","text":"Model Data Analysis \u00b6 Python libraries and the EMME python \u00b6 In general the RTM uses the default python libraries installed with the EMME python. In some cases this means foregoing features that have been recently introduced or having code that is not compatible with python installations outside EMME. However, it ensures that the RTM will run without further configuration providing the user has installed the correct version of EMME. Python + util \u00b6 The RTM scripting employs a utility toolbox that creates functions for repeated operations. It is worth familiarizing yourself with the functions here as they are often employed outside the RTM run itself to post-process data. For example, util can be used to create a pandas dataframe for full matrices and append RTM matrices to it for further analysis or plotting in python. import inro.modeller as _m util = _m.Modeller().tool(\"translink.util\") eb = _m.Modeller().emmebank df = util.get_pd_ij_df(eb) # create a longform pandas dataframe for full matrices # add columns for light and heavy truck OD tables to the data frame df['amLGVDemand'] = util.get_matrix_numpy(eb, \"mfLGVAM\").flatten() df['amHGVDemand'] = util.get_matrix_numpy(eb, \"mfHGVAM\").flatten() Which yields the following results: In the above example matrix names or numbers can be used to access the data in util.get_matrix_numpy() . Data extraction using variables of interest tool \u00b6 In this example we use a spreadsheet to build a sqlite database. This tools allows the user to create tables and fields within a table using EMME matrix calculations. The Variables_of_Interest.xlsx spreadsheet is located in the RTM/Scripts/Phase3Analytics folder. Setting up the spreadsheet \u00b6 The Datamap tab describes what each field does in the Sheet1 tab. The Sheet1 tab is used to build the database. A simple matrix calculation can be used to extract data. Entering the following in Sheet1 will create a table in the output sqlite database with AM demand for light and heavy goods vehicles equivalent to the pandas data frame example above: In addition to simple data extraction, new data can be generated based on RTM outputs using EMME matrix calculator expressions. For example, we can create a matrix of the minimum time on transit between all zones considering both the bus and rail modes. Note that we can reference EMME matrices by name or number. Warning All Attributes (fields) associated with the same Category (table) must be of the same dimension. For example, full matrices (MF) and vectors (MO/MD) must be placed in separate tables. Running the Modeller Tool \u00b6 Once you have specified the data you wish to output in in Sheet1 , the modeller tool Variables of Interest Extraction located in the Phase3Analytics Toolbox can be run to produce the outputs. Note This tool requires the installation of one additional python library. Installation instructions can be found in the tool documentation at RTM/Documentation/ToolDoc_VariablesOfInterest.pdf . To create the database with your specified tables and fields simply run the tool with the appropriate sheet name in the field. If you have not changed the name from Sheet1 there is nothing to update and you can simply run the tool. Note The name Sheet1 can be changed to any Excel allowable name. The chosen name needs to be passed to the tool either in the modeller interface or the function call. Viewing results \u00b6 The requested results will be output to a sqlite database named Variables_of_Interest_Results.db . The output can be viewed in the same manner as the trip_summaries.db and rtm.db discussed here","title":"Model Data Analysis"},{"location":"data_analysis/#model-data-analysis","text":"","title":"Model Data Analysis"},{"location":"data_analysis/#python-libraries-and-the-emme-python","text":"In general the RTM uses the default python libraries installed with the EMME python. In some cases this means foregoing features that have been recently introduced or having code that is not compatible with python installations outside EMME. However, it ensures that the RTM will run without further configuration providing the user has installed the correct version of EMME.","title":"Python libraries and the EMME python"},{"location":"data_analysis/#python-util","text":"The RTM scripting employs a utility toolbox that creates functions for repeated operations. It is worth familiarizing yourself with the functions here as they are often employed outside the RTM run itself to post-process data. For example, util can be used to create a pandas dataframe for full matrices and append RTM matrices to it for further analysis or plotting in python. import inro.modeller as _m util = _m.Modeller().tool(\"translink.util\") eb = _m.Modeller().emmebank df = util.get_pd_ij_df(eb) # create a longform pandas dataframe for full matrices # add columns for light and heavy truck OD tables to the data frame df['amLGVDemand'] = util.get_matrix_numpy(eb, \"mfLGVAM\").flatten() df['amHGVDemand'] = util.get_matrix_numpy(eb, \"mfHGVAM\").flatten() Which yields the following results: In the above example matrix names or numbers can be used to access the data in util.get_matrix_numpy() .","title":"Python + util"},{"location":"data_analysis/#data-extraction-using-variables-of-interest-tool","text":"In this example we use a spreadsheet to build a sqlite database. This tools allows the user to create tables and fields within a table using EMME matrix calculations. The Variables_of_Interest.xlsx spreadsheet is located in the RTM/Scripts/Phase3Analytics folder.","title":"Data extraction using variables of interest tool"},{"location":"data_analysis/#setting-up-the-spreadsheet","text":"The Datamap tab describes what each field does in the Sheet1 tab. The Sheet1 tab is used to build the database. A simple matrix calculation can be used to extract data. Entering the following in Sheet1 will create a table in the output sqlite database with AM demand for light and heavy goods vehicles equivalent to the pandas data frame example above: In addition to simple data extraction, new data can be generated based on RTM outputs using EMME matrix calculator expressions. For example, we can create a matrix of the minimum time on transit between all zones considering both the bus and rail modes. Note that we can reference EMME matrices by name or number. Warning All Attributes (fields) associated with the same Category (table) must be of the same dimension. For example, full matrices (MF) and vectors (MO/MD) must be placed in separate tables.","title":"Setting up the spreadsheet"},{"location":"data_analysis/#running-the-modeller-tool","text":"Once you have specified the data you wish to output in in Sheet1 , the modeller tool Variables of Interest Extraction located in the Phase3Analytics Toolbox can be run to produce the outputs. Note This tool requires the installation of one additional python library. Installation instructions can be found in the tool documentation at RTM/Documentation/ToolDoc_VariablesOfInterest.pdf . To create the database with your specified tables and fields simply run the tool with the appropriate sheet name in the field. If you have not changed the name from Sheet1 there is nothing to update and you can simply run the tool. Note The name Sheet1 can be changed to any Excel allowable name. The chosen name needs to be passed to the tool either in the modeller interface or the function call.","title":"Running the Modeller Tool"},{"location":"data_analysis/#viewing-results","text":"The requested results will be output to a sqlite database named Variables_of_Interest_Results.db . The output can be viewed in the same manner as the trip_summaries.db and rtm.db discussed here","title":"Viewing results"},{"location":"data_generate/","text":"Custom Data Generation \u00b6 Python script vs modeller tool \u00b6 In general Modeller tools more polished and can provide a GUI, but take more time and effort to prepare. They can still be called from other places and imported into other files. We generally use these for production grade, stable solutions, that we intend to use repeatedly. Object oriented. It is expected that everyone here knows how to use a modeller tool Python script can be built easily and often is enough to quickly complete a task at hand. Maybe fragile, can break with simple model changes. These may not be maintained. These can work will with the notebooks. They can just work with basic functions, easy to put together a basic but reproducible analysis. Executing a python script from the EMME iPython shell \u00b6 Open the ipython modeller shell in EMME desktop Once in the shell, navigate to location of the subject script. In this case the script in question is located in the RTM/Scripts/Tools directory Check the files in this directory to ensure we have the one we want, then we can use the iPython magic %run <filename.py> to execute our script Example Tool for PA to OD \u00b6 As a general rule in trip based modeling production/attraction (PA) trips can be converted to origin/destination (OD) trips roughly by 0.5 * (mat + mat') . However, for a variety of reasons, most notably non-home-based (NHB) trips, not everything is completely symmetrical. Production to attraction blending factors have been calculated from the trip diary for the RTM skims. The example runs the PA2OD.py python script with the output directed to the trip_summaries.db database. Once you have run the script, navigate to RTM/<your_db_folder> and open the trip_summaries.db in your sqlite viewer. Once there, we will see a new table named od_daily_<your ensemble if any> From there we can query and view the results Why does it run? \u00b6 if __name__ == '__main__': eb = _m.Modeller().emmebank # run with ensemble name and ensem_agg = True to aggregate # run with no ensemble name and ensem_agg = False to get TAZ level results # note, TAZ level results create very large file main(eb, ensem='gy', ensem_agg=True) And why does this work? See this video on Youtube Name and Main Using the notebook \u00b6","title":"Custom Data Generation"},{"location":"data_generate/#custom-data-generation","text":"","title":"Custom Data Generation"},{"location":"data_generate/#python-script-vs-modeller-tool","text":"In general Modeller tools more polished and can provide a GUI, but take more time and effort to prepare. They can still be called from other places and imported into other files. We generally use these for production grade, stable solutions, that we intend to use repeatedly. Object oriented. It is expected that everyone here knows how to use a modeller tool Python script can be built easily and often is enough to quickly complete a task at hand. Maybe fragile, can break with simple model changes. These may not be maintained. These can work will with the notebooks. They can just work with basic functions, easy to put together a basic but reproducible analysis.","title":"Python script vs modeller tool"},{"location":"data_generate/#executing-a-python-script-from-the-emme-ipython-shell","text":"Open the ipython modeller shell in EMME desktop Once in the shell, navigate to location of the subject script. In this case the script in question is located in the RTM/Scripts/Tools directory Check the files in this directory to ensure we have the one we want, then we can use the iPython magic %run <filename.py> to execute our script","title":"Executing a python script from the EMME iPython shell"},{"location":"data_generate/#example-tool-for-pa-to-od","text":"As a general rule in trip based modeling production/attraction (PA) trips can be converted to origin/destination (OD) trips roughly by 0.5 * (mat + mat') . However, for a variety of reasons, most notably non-home-based (NHB) trips, not everything is completely symmetrical. Production to attraction blending factors have been calculated from the trip diary for the RTM skims. The example runs the PA2OD.py python script with the output directed to the trip_summaries.db database. Once you have run the script, navigate to RTM/<your_db_folder> and open the trip_summaries.db in your sqlite viewer. Once there, we will see a new table named od_daily_<your ensemble if any> From there we can query and view the results","title":"Example Tool for PA to OD"},{"location":"data_generate/#why-does-it-run","text":"if __name__ == '__main__': eb = _m.Modeller().emmebank # run with ensemble name and ensem_agg = True to aggregate # run with no ensemble name and ensem_agg = False to get TAZ level results # note, TAZ level results create very large file main(eb, ensem='gy', ensem_agg=True) And why does this work? See this video on Youtube Name and Main","title":"Why does it run?"},{"location":"data_generate/#using-the-notebook","text":"","title":"Using the notebook"},{"location":"data_outputs/","text":"Model Data Output \u00b6 Exporting full matrix directory \u00b6 The RTM produces a lot of data for each run, there are more than 1,000 full matrices at the end of a run. It's sometimes difficult to know what data is available afterwards. EMME desktop provides a full matrix directory, but it is not directly searchable. However if we open the worksheet located here: Worksheets/Tables/EMME Standard - GENERAL/General/Matrices/Matrix directory - Full matrices (mf) Clicking on the icon that looks like a database table opens the worksheet as a datatable. A datatable is effectively a sqlite database table. Click the save as button Removing spaces in the name simplifies later querying. The matrix directory will be saved at the project level in the RTM\\data_tables.db sqlite database, which we will query in the next section. Searching for matrices \u00b6 Now that we have the full matrix directory saved at the project level in the RTM\\data_tables.db sqlite database, we can use SQL to search for matrices that are of interest. Although there are a number of ways to access the database we recommend a sqlite viewer such as SQLite Studio Suppose we are interested in commute trips and want to find home-based work production attraction (PA) matrices. We can open the database in the sqlite viewer and execute the following query SELECT Matrix ,[Name] ,[Description] FROM Fullmatrixdirectory WHERE 1=1 and UPPER([Name]) LIKE '%HBW%' or UPPER([Name]) LIKE '%WORK%' or UPPER([Description]) LIKE '%HBW%' or UPPER([Description]) LIKE '%WORK%' Which yields the following results We get 164 records, but can see the matrices we want highlighted in the red box. Changing the WHERE clause returns only the results we want: SELECT Matrix ,[Name] ,[Description] FROM Fullmatrixdirectory WHERE 1=1 and UPPER([Name]) LIKE 'HBWP-A%' Now we get only 9 results, 3 income categories by 3 auto ownership levels Changing the WHERE clause as follows let's us see the PA tables for all home-based purposes SELECT Matrix ,[Name] ,[Description] FROM Fullmatrixdirectory WHERE 1=1 and UPPER([Name]) LIKE 'HB%P-A%' Note that we get 55 records. There are 7 home-based purposes, but home-based university does not have income and auto-ownership distinction so 6 x 9 + 1 = 55. Finally, we can add an 'N' to the WHERE clause to see the non-home-based purposes. SELECT Matrix ,[Name] ,[Description] FROM Fullmatrixdirectory WHERE 1=1 and UPPER([Name]) LIKE 'NH%P-A%' And here we get 2 records because there are 2 non-home-based purposes and they do not have income and auto-ownership distinction. Similar methods can be used to find other data of interest Using the rtm and trip summaries databases \u00b6","title":"Model Data Output"},{"location":"data_outputs/#model-data-output","text":"","title":"Model Data Output"},{"location":"data_outputs/#exporting-full-matrix-directory","text":"The RTM produces a lot of data for each run, there are more than 1,000 full matrices at the end of a run. It's sometimes difficult to know what data is available afterwards. EMME desktop provides a full matrix directory, but it is not directly searchable. However if we open the worksheet located here: Worksheets/Tables/EMME Standard - GENERAL/General/Matrices/Matrix directory - Full matrices (mf) Clicking on the icon that looks like a database table opens the worksheet as a datatable. A datatable is effectively a sqlite database table. Click the save as button Removing spaces in the name simplifies later querying. The matrix directory will be saved at the project level in the RTM\\data_tables.db sqlite database, which we will query in the next section.","title":"Exporting full matrix directory"},{"location":"data_outputs/#searching-for-matrices","text":"Now that we have the full matrix directory saved at the project level in the RTM\\data_tables.db sqlite database, we can use SQL to search for matrices that are of interest. Although there are a number of ways to access the database we recommend a sqlite viewer such as SQLite Studio Suppose we are interested in commute trips and want to find home-based work production attraction (PA) matrices. We can open the database in the sqlite viewer and execute the following query SELECT Matrix ,[Name] ,[Description] FROM Fullmatrixdirectory WHERE 1=1 and UPPER([Name]) LIKE '%HBW%' or UPPER([Name]) LIKE '%WORK%' or UPPER([Description]) LIKE '%HBW%' or UPPER([Description]) LIKE '%WORK%' Which yields the following results We get 164 records, but can see the matrices we want highlighted in the red box. Changing the WHERE clause returns only the results we want: SELECT Matrix ,[Name] ,[Description] FROM Fullmatrixdirectory WHERE 1=1 and UPPER([Name]) LIKE 'HBWP-A%' Now we get only 9 results, 3 income categories by 3 auto ownership levels Changing the WHERE clause as follows let's us see the PA tables for all home-based purposes SELECT Matrix ,[Name] ,[Description] FROM Fullmatrixdirectory WHERE 1=1 and UPPER([Name]) LIKE 'HB%P-A%' Note that we get 55 records. There are 7 home-based purposes, but home-based university does not have income and auto-ownership distinction so 6 x 9 + 1 = 55. Finally, we can add an 'N' to the WHERE clause to see the non-home-based purposes. SELECT Matrix ,[Name] ,[Description] FROM Fullmatrixdirectory WHERE 1=1 and UPPER([Name]) LIKE 'NH%P-A%' And here we get 2 records because there are 2 non-home-based purposes and they do not have income and auto-ownership distinction. Similar methods can be used to find other data of interest","title":"Searching for matrices"},{"location":"data_outputs/#using-the-rtm-and-trip-summaries-databases","text":"","title":"Using the rtm and trip summaries databases"},{"location":"workflow/","text":"Model Workflow \u00b6 In this section, we will show you the best practices when working with the RTM from setting up your environment to extracting model results. Requirements \u00b6 We encourage all users and developers to be familiar with EMME as well as the RTM development stack: python , SQL and git . If you are new to EMME, we recommend you to take EMME Training Courses . If you are new to programming, you should go through some online tutorials and documentations for python , SQL and git before proceeding. Licensed installation of EMME Desktop 4.4.2 Installation of git Installation of git lfs Installation of SQLite Studio Installation of Visual Studio Code (optional) Note A valid EMME license is required to run the RTM. See Contributing if you need help obtaining a license or need access to the RTM. Cloning the Model \u00b6 To get the latest version of the rtm, clone it from the RTM github repository. The following bash commands will clone the repository from the master branch, and fetch the latest commit with large file storage support. Then, it will checkout the current branch into a new branch named master_working_01 . We recommend that you rename the new branch based on the project you are working on: git clone https://github.com/TransLinkForecasting/rtm.git --branch master --single-branch cd rtm/ git fetch --all git lfs install git lfs pull git checkout -b 'master_working_01' To clone a specific official release, replace master with a version tag such as RTM3.3 . If this is the first time you use git, you might need to set your name and email for git commits, see Git Setup . Update File References \u00b6 EMME toolbox stores absolute paths and they need to be updated when the model has been copied or moved to a new directory. Please also run the following after you clone the model: cd 'RTM/Scripts/' bash 'relocate_tools.sh' Alternatively, you can run the batch file RTM\\Scripts\\relocate_tools.bat on Windows. Folder Structure \u00b6 The RTM is delivered as a collection of input files in the BaseNetworks/ folder with a collection of python scripts in Scripts/ folder. The EMME project file RTM.emp reference all required folders and is loaded with a Minimal Base Databank stored in Template/ folder. Before running the model, familiarize yourself with the model folder structure. RTM/ \u251c\u2500\u2500 BaseNetworks/ \u2502 \u2514\u2500\u2500 Inputs/ | \u251c\u2500\u2500 Documentation/ \u251c\u2500\u2500 Logbook/ \u251c\u2500\u2500 Media/ \u251c\u2500\u2500 Scripts/ \u251c\u2500\u2500 Template/ \u251c\u2500\u2500 Views/ \u251c\u2500\u2500 Worksheets/ | \u2514\u2500\u2500 RTM.emp Warning Do not delete the Minimal Base Databank in EMME or the Template/ folder. This is an empty placeholder databank that is packaged with the RTM to enable the initialization of databank through EMME Modeler or EMME Notebook. Base Networks Folder \u00b6 The base network folder contains files required to build a databank from scratch. Each set of files in the main BaseNetworks/ supply input data for each scenario year (for example: 2017, 2035, 2050), the set of files can be mainly classified as the following: Network batchin files: base_network_*.txt , link_shape_*.txt , etc Calibration factors (K-factors): dist_factors_gy.csv.gz External demand, bike scores: externals_bikescore_*.csv.gz Starter Skims: start_skims.csv.gz Fare zones: fare_zones_travelled.csv.gz Definition of ensembles: taz1700_ensembles.csv Definition of modes: modes.in Definition of transit vehicles: tvehicles.in Demographics and geographics of Metro Vancouver: taz1700_demographics_*.csv , taz1700_geographics_*.csv Geographic dummies: taz1700_dummies.csv Park and ride assumptions: taz1700_pnr.csv Time slicing: time_slicing.csv , time_slicing_gb.csv Transit bias calibrations: transit_adj.csv Truck model batch files: TruckBatchFiles/* RTM/ \u251c\u2500\u2500 BaseNetworks/ \u2502 \u251c\u2500\u2500 base_network_*.txt \u2502 \u251c\u2500\u2500 link_shape_*.txt \u2502 \u251c\u2500\u2500 turns_*.txt \u2502 \u251c\u2500\u2500 transit_lines_*.txt \u2502 \u251c\u2500\u2500 extra_nodes_*.txt \u2502 \u251c\u2500\u2500 extra_links_*.txt \u2502 \u251c\u2500\u2500 extra_turns_*.txt \u2502 \u251c\u2500\u2500 extra_transit_lines_*.txt \u2502 \u251c\u2500\u2500 dist_factors_gy.csv.gz \u2502 \u251c\u2500\u2500 externals_bikescore_*.csv.gz \u2502 \u251c\u2500\u2500 fare_zones_travelled.csv.gz \u2502 \u251c\u2500\u2500 start_skims.csv.gz \u2502 \u251c\u2500\u2500 taz1700_ensembles.csv \u2502 \u251c\u2500\u2500 modes.in \u2502 \u251c\u2500\u2500 tvehicles.in \u2502 | \u2502 \u2514\u2500\u2500 Inputs/ \u2502 \u251c\u2500\u2500 taz1700_demographics_*.csv \u2502 \u251c\u2500\u2500 taz1700_geographics_*.csv \u2502 \u251c\u2500\u2500 taz1700_dummies.csv \u2502 \u251c\u2500\u2500 taz1700_pnr.csv \u2502 \u251c\u2500\u2500 time_slicing.csv \u2502 \u251c\u2500\u2500 time_slicing_gb.csv \u2502 \u251c\u2500\u2500 transit_adj.csv | \u2514\u2500\u2500 TruckBatchFiles/ \u2502 \u251c\u2500\u2500 *AsiaPacificv1.txt \u2502 \u251c\u2500\u2500 *CrossBorderv1.txt \u2502 \u251c\u2500\u2500 IRBatchIn.txt \u2502 \u251c\u2500\u2500 PMVActivity.txt | \u2514\u2500\u2500 RGBatchIn.txt \u2514\u2500\u2500 ... Scripts Folder \u00b6 This folder contains python scripts used to run the model: Toolbox relocate tool: relocate_tools.bat , relocate_tools.sh , toolbox_modify.py Model Scripts toolbox: Phase3Scripts/ Analytics toolbox: Phase3Analytics/ Model utility toolbox: util/ Model tools, scripts and notebooks of model initialization and model runs: util/ RTM/ \u251c\u2500\u2500 Scripts/ \u2502 \u251c\u2500\u2500 relocate_tools.bat \u2502 \u251c\u2500\u2500 relocate_tools.sh \u2502 \u251c\u2500\u2500 toolbox_modify.py \u2502 | \u2502 \u251c\u2500\u2500 Phase3Scripts/ \u2502 \u251c\u2500\u2500 Phase3Analytics/ \u2502 \u251c\u2500\u2500 util/ \u2502 \u2514\u2500\u2500 Tools/ \u2514\u2500\u2500 ... Note The Scripts control the model behavior of the RTM. You are free to go through the script to familiarize with the implementation of the model. For more information regarding the modeling structure of the RTM, modeling decisions, data sources, estimation of sub models, please contact us . Other Folders \u00b6 Media folder Contains shapefiles, ArcGIS maps. Output data are typically stored here. Documentation folder contains printable user manuals. Logbook folder contains EMME logbook information generated by EMME Modeler tools. Template folder provides an empty databank that allow Modeler to initialize new RTM databanks. View folder contains standard views provided in the EMME environment. Worksheets folder contains standardized worksheets in the EMME environment. RTM/ \u251c\u2500\u2500 Media/ \u251c\u2500\u2500 Documentation/ \u251c\u2500\u2500 Logbook/ \u251c\u2500\u2500 Template/ \u251c\u2500\u2500 Views/ \u251c\u2500\u2500 Worksheets/ \u2514\u2500\u2500 ... Initialize Databank \u00b6 You can initialize a single databank using the EMME Modeler or initialize multiple databanks using EMME Notebook, depending on your need. To start the EMME, open the file. This will launch EMME, open the Minimal Base Databank's Placeholder Scenario when prompted. With EMME Modeler \u00b6 To open Modeler, click on the EMME Modeler icon . Once the Modeler opens, find Translink RTM Phase 3 Model toolbox and open the Initialize Emmebank tool: Enter a folder name and a name for the databank. Try to be descriptive. For example, if this is a databank for editing or debugging network only, name it network_edit_something , if this is a final copy of a new business as usual run for year 2050, name it 00_BAU_2050 . Once you enter the names, click > Run . Once the run is completed, the Tool complete message will appear. With EMME Notebook \u00b6 If you are comfortable with python and Jupyter Notebook, we strongly recommend that you use EMME Notebook to initialize databanks. This improves the reproducibility of your model run. This is generally not needed for network scenario or testing, but for final copy of a run, it is highly recommend. To open EMME Notebook, click on the EMME Notebook icon . The EMME Notebook should open in your browser, if it didn't open automatically, look for http://localhost:xxxx/ in the EMME - Notebook command prompt window. The default is usually http://localhost:8888/ . Once opened, you should see a list of folders in the Scripts/ folder. Go to Tools/ folder and make a duplicate of init_many.ipynb , name it to something more descriptive for your use, like init_many_00_BAU_2050.ipynb , then open it. Modify params as needed, run the entire script to initialize the databank. Build Scenario \u00b6 There are a wide range of changes you can make to the EMME base model for your study. We won't be able to cover them all in detail here, but here are some examples of model changes: demographics new roads or bridges new transit lines new transit stops transit fare tolls mobility pricing park and ride pricing etc... Network editing \u00b6 The EMME Network Editor provides users the ability to create and modify nodes, links, turns, transit lines, and transit segments. We will use a BRT line example to illustrate how to add modes and vehicles for the RTM, and edit networks in EMME. Custom Inputs \u00b6 There are a number of custom inputs that the RTM uses at model initialization and run time to modify model behavior: At initiation Transit vehicles and modes At runtime Required files with model data demographic and geographic Optional files to manipulate model data Scalars: custom_scalars.csv Network: custom_network.txt Transit Lines: custom_tline.txt Transit Segment: custom_tseg.txt The optional custom_<datatype> series files can be placed in the RTM/<your run directory>/inputs folder of the RTM instance. These files are imported after the main model setup ( create scenarios and data import ) and can be used to change any model setting held in a scalar matrix or execute an arbitrary set of network link, transit line, or transit segment calculations. Files with a .csv extension indicate comma delimited data while files with a .txt extension indicate tab delimited data. Warning Do not leave a trailing new line or carriage return at the end of the files custom_<datatype>.txt files. In addition, there can be only one file of each name in the inputs folder. Custom Scalars \u00b6 This file allow the user to change data held in scalar matrices in the scripting without changing the scripting. This in turn allows the user to run multiple runs with the same scripts and different scalar matrix data. The custom_scalars.csv file has headers and requires the following information in comma delimited format. Matrix ID Matrix Name Matrix Description Value The EMME Matrix ID number The EMME Matrix Name The EMME Matrix Description The value to change Below is an example of changing the auto operating cost using the custom scalars file. Custom Network \u00b6 This file allows the user to execute an arbitrary set of network link calculations prior to running the model. The custom_network.txt file should not have headers and requires the following information in tab delimited format Period Result Expression Selection Aggregation AM, MD, PM, or ALL Where the calculation should be stored (for instance @capacity) The network calculation to be executed Which link(s) to execute the calculation on (optional - can be left blank to update all links) Results aggregation (optional and generally left blank) Below is an example of removing one lane and reducing capacity on links 111902-111904 and 111904-111902, and setting the signal delay to 0 for all links that are not VDF 14 for all three assignment periods. Note that there is no carriage return on the last line. Custom Transit Lines \u00b6 This file allows the user to execute an arbitrary set of network transit line calculations prior to running the model. The custom_tline.txt file should not have headers and requires the following information in tab delimited format Period Result Expression Selection Aggregation AM, MD, PM, or ALL Where the calculation should be stored (for instance hdw) The network calculation to be executed Which line(s) to execute the calculation on (optional - can be left blank to update all lines) Results aggregation (optional and generally left blank) Below is an example of reducing the headway on all lines except those in the Fraser Valley during the AM and PM peak hours, and setting the signal delay to 0 for all links that are not VDF 14 for all three assignment periods. Note that there is no carriage return on the last line. Custom Transit Segments \u00b6 This file allows the user to execute an arbitrary set of network transit segment calculations prior to running the model. The custom_tseg.txt file should not have headers and requires the following information in tab delimited format Period Result Expression Selection Aggregation AM, MD, PM, or ALL Where the calculation should be stored (for instance ttf) The network calculation to be executed Which line(s) to execute the calculation on (optional - can be left blank to update all lines) Results aggregation (optional and generally left blank) Below is an example of changing the transit time function (ttf) on links 111902-111904 and 111904-111902 to ttf2. Note that there is no carriage return on the last line. Example: 2050 BRT Line \u00b6 Similar to most model application exercises, in our example, there are two main components of changes we are making to the 2050 base model: network editing and model custom inputs. Network editing - adding a new transit line Custom inputs Add congestion pricing to the network with custom_network.txt input file Use a custom demographic file for corridor intensification Step 1: create new scenarios \u00b6 Duplicate the base scenario input files, and rename them with a new scenario number. For example, if you are making changes on top of scenario \"5000\", name it \"5001\", \"5002\". Once you added all the scenarios, add these new scenario numbers into the InitEmmebank.py script. This will allow the initialize emmebank modeler tool to load the new scenarios. Step 2: add new modes \u00b6 Before we create a new transit line, we need to make sure the mode and the vehicle of is available, add the new mode to modes.in file in the base network folder: Then check the tvehicles.in file in the base network folder: Note After the modes are added, it won't be available in the already initialized databank and scenario. You should re-initialize a working copy of the databank. Now, you will need to initialize a new databank with the new scenario number, mode, and vehicle. You can give it a descriptive and abbreviated name such as 01_Lg_BRT_CP_LU_2050 . Step 3: perform network editing \u00b6 Open EMME network editor , add notes, links, and transit line as needed. Make sure you save a copy of the build file before you save and exit the scenario. Build files can be created from any changes you made while in the Network Editor. The build file is a great way to save and replicate model network changes. If you have a build file, you can stage it and run the changes. * Copy your build file to Network_builds/ folder. * Open \"Network History and Builds\" prompt from EMME Network Editor . Click the folder icon to \"Add network builds\", then click \"Stage\". * Preview the build, then run the build: Step 4: set up custom inputs \u00b6 For the BRT example, we will use custom_network.txt and a simple 8-zone shapefile to add congestion pricing attribute to the network in batch. We will also load a custom demographic file with 20% population intensification along the study corridor. The custom input file such as custom_network.txt needs to be placed in the Input/ folder within the emme databank folder, such as the folder db_01_Lg_BRT_CP_LU_2050 or 01_Lg_BRT_CP_LU_2050 . (Do not place the file in the BaseNetworks folder!) The custom demographic file such as taz1700_demographics_2050-20.csv needs to be selected as the demographic input when running the model. Export Scenario \u00b6 While in most cases your current databank for the alternative scenario is ready to run, it is important to export your new scenario network and organize all input files into a sub folder within the Scenario_Inputs folder. This allows you to share your new scenario with other users without needing to copy the entire databank with results. This also allow you to quickly reinitialize the scenario to run on a newer version of the RTM. Export Network \u00b6 To export your scenario's network, open EMME Modeler: Then select your new scenario to export: Organize Scenario Inputs \u00b6 We highly recommend that you store every input required to rebuild your new scenario and replicate your model run within a sub folder of the Scenario_Inputs folder. For our example, this would be the folder structure for all the changes we have made in our BRT example: RTM/ \u251c\u2500\u2500 Scenario_Inputs/ \u2502 \u2514\u2500\u2500 01_2050-20-hw8-cp_Lg_BRT-g/ \u2502 \u251c\u2500\u2500 custom_network.txt \u2502 \u251c\u2500\u2500 modes.in \u2502 \u251c\u2500\u2500 tvehicles.in \u2502 \u2502 \u2502 \u251c\u2500\u2500 BaseNetworks/ \u2502 \u2502 \u251c\u2500\u2500 Inputs/ \u2502 \u2502 \u2502 \u2514\u2500\u2500 taz1700_demographics_2050-20.csv \u2502 \u2502 \u251c\u2500\u2500 base_network_5001.txt \u2502 \u2502 \u2514\u2500\u2500 ... \u2502 \u251c\u2500\u2500 Scripts/Phase3Scripts/ \u2502 \u2502 \u251c\u2500\u2500 Tools/ \u2502 \u2502 \u2502 \u2502\u2500\u2500 init_many_example_lgrt.ipynb \u2502 \u2502 \u2502 \u2514\u2500\u2500 run_many_example_lgrt.ipynb \u2502 \u2502 \u2514\u2500\u2500 Phase3Scripts/ \u2502 \u2502 \u2514\u2500\u2500 InitEmmebank.py \u2502 \u2514\u2500\u2500 Media/ \u2502 \u2514\u2500\u2500 RTM_8ZonePolygon.shp \u2514\u2500\u2500 ... Run Model \u00b6 You can run the model using a single databank using the EMME Modeler or run multiple databanks using the EMME Notebook, depending on your need. EMME Modeler \u00b6 Once you have set up all the input files in the databank, such as customized demographics, custom input files, etc, you are ready to do a full model run using the EMME Modeler. To open Modeler, click on the EMME Modeler icon . Find Translink RTM Phase 3 Model toolbox and open the Run RTM3 tool: Change the Full Model Run settings as needed. Make sure to enter the correct model horizon year, scenario, demographic and geographic inputs. Click Run . Each model run can take 2 to 4 hours depending on the custom settings and scenario. Warning Do not interrupt the model run. The RTM model is not designed to be run in separate stages or run multiple times. If you stopped a model run before it is done, you should start over - reinitialize the databank and start run. EMME Notebook \u00b6 The EMME Notebook allows you to create .ipynb scripts that handles multiple model runs and runs with complex set up. It is ideal for our BRT example where we needed to perform link tagging and use custom network input file for congestion pricing. To open EMME Notebook, click on the EMME Notebook icon . The EMME Notebook should open in your browser, if it didn't open automatically, look for http://localhost:xxxx/ in the EMME - Notebook command prompt window. The default is usually http://localhost:8888/ . Once opened, you should see a list of folders in the Scripts/ folder. Go to Tools/ folder and make a duplicate of run_many.ipynb , name it to something more descriptive for your use, like run_many_00_BAU_2050.ipynb or run_many_example_lgrt.ipynb , then open it. Modify params as needed. Make sure you carefully review the script associated with the model run. You may need to add new code to this section depending on the requirements of your model run. Run the entire script to perform the full model run with custom settings. Commit Changes \u00b6 If this is your first time using git after an installation, see Git Setup . While working with the RTM on git, here are some ground rules: Main project branches ( master , example_brt_proj ) are always protected. Push a temp branch then do pull request to merge your changes Only stage and commit model inputs and settings, never databanks Any scenario-specific changes for scripts should be placed into Scenario_Inputs for commit Organize a Scenario_Inputs folder when you finish a scenario Use active verb for commit messages, like \"add scenario inputs for brt examples.\" Warning Do not commit the databank associated with the model run. We recommend you to place the databank folders in your version of the .gitignore . When staging and committing model changes, think about what other users or developers may need to run your scenario from scratch. Commit inputs and set up, not the results. Push Changes to GitHub \u00b6 If you are a collaborator, you may push your changes to the rtm repository on GitHub. You will not be able to push directly to most of the branches already on the rtm repository as they are protected, so always push your working branch and merge to any main branch with a pull request. An admin will review your changes when you submit a pull request. git push origin master_your-project Learn more about git and read more about GitHub pull request .","title":"Model Workflow"},{"location":"workflow/#model-workflow","text":"In this section, we will show you the best practices when working with the RTM from setting up your environment to extracting model results.","title":"Model Workflow"},{"location":"workflow/#requirements","text":"We encourage all users and developers to be familiar with EMME as well as the RTM development stack: python , SQL and git . If you are new to EMME, we recommend you to take EMME Training Courses . If you are new to programming, you should go through some online tutorials and documentations for python , SQL and git before proceeding. Licensed installation of EMME Desktop 4.4.2 Installation of git Installation of git lfs Installation of SQLite Studio Installation of Visual Studio Code (optional) Note A valid EMME license is required to run the RTM. See Contributing if you need help obtaining a license or need access to the RTM.","title":"Requirements"},{"location":"workflow/#cloning-the-model","text":"To get the latest version of the rtm, clone it from the RTM github repository. The following bash commands will clone the repository from the master branch, and fetch the latest commit with large file storage support. Then, it will checkout the current branch into a new branch named master_working_01 . We recommend that you rename the new branch based on the project you are working on: git clone https://github.com/TransLinkForecasting/rtm.git --branch master --single-branch cd rtm/ git fetch --all git lfs install git lfs pull git checkout -b 'master_working_01' To clone a specific official release, replace master with a version tag such as RTM3.3 . If this is the first time you use git, you might need to set your name and email for git commits, see Git Setup .","title":"Cloning the Model"},{"location":"workflow/#update-file-references","text":"EMME toolbox stores absolute paths and they need to be updated when the model has been copied or moved to a new directory. Please also run the following after you clone the model: cd 'RTM/Scripts/' bash 'relocate_tools.sh' Alternatively, you can run the batch file RTM\\Scripts\\relocate_tools.bat on Windows.","title":"Update File References"},{"location":"workflow/#folder-structure","text":"The RTM is delivered as a collection of input files in the BaseNetworks/ folder with a collection of python scripts in Scripts/ folder. The EMME project file RTM.emp reference all required folders and is loaded with a Minimal Base Databank stored in Template/ folder. Before running the model, familiarize yourself with the model folder structure. RTM/ \u251c\u2500\u2500 BaseNetworks/ \u2502 \u2514\u2500\u2500 Inputs/ | \u251c\u2500\u2500 Documentation/ \u251c\u2500\u2500 Logbook/ \u251c\u2500\u2500 Media/ \u251c\u2500\u2500 Scripts/ \u251c\u2500\u2500 Template/ \u251c\u2500\u2500 Views/ \u251c\u2500\u2500 Worksheets/ | \u2514\u2500\u2500 RTM.emp Warning Do not delete the Minimal Base Databank in EMME or the Template/ folder. This is an empty placeholder databank that is packaged with the RTM to enable the initialization of databank through EMME Modeler or EMME Notebook.","title":"Folder Structure"},{"location":"workflow/#base-networks-folder","text":"The base network folder contains files required to build a databank from scratch. Each set of files in the main BaseNetworks/ supply input data for each scenario year (for example: 2017, 2035, 2050), the set of files can be mainly classified as the following: Network batchin files: base_network_*.txt , link_shape_*.txt , etc Calibration factors (K-factors): dist_factors_gy.csv.gz External demand, bike scores: externals_bikescore_*.csv.gz Starter Skims: start_skims.csv.gz Fare zones: fare_zones_travelled.csv.gz Definition of ensembles: taz1700_ensembles.csv Definition of modes: modes.in Definition of transit vehicles: tvehicles.in Demographics and geographics of Metro Vancouver: taz1700_demographics_*.csv , taz1700_geographics_*.csv Geographic dummies: taz1700_dummies.csv Park and ride assumptions: taz1700_pnr.csv Time slicing: time_slicing.csv , time_slicing_gb.csv Transit bias calibrations: transit_adj.csv Truck model batch files: TruckBatchFiles/* RTM/ \u251c\u2500\u2500 BaseNetworks/ \u2502 \u251c\u2500\u2500 base_network_*.txt \u2502 \u251c\u2500\u2500 link_shape_*.txt \u2502 \u251c\u2500\u2500 turns_*.txt \u2502 \u251c\u2500\u2500 transit_lines_*.txt \u2502 \u251c\u2500\u2500 extra_nodes_*.txt \u2502 \u251c\u2500\u2500 extra_links_*.txt \u2502 \u251c\u2500\u2500 extra_turns_*.txt \u2502 \u251c\u2500\u2500 extra_transit_lines_*.txt \u2502 \u251c\u2500\u2500 dist_factors_gy.csv.gz \u2502 \u251c\u2500\u2500 externals_bikescore_*.csv.gz \u2502 \u251c\u2500\u2500 fare_zones_travelled.csv.gz \u2502 \u251c\u2500\u2500 start_skims.csv.gz \u2502 \u251c\u2500\u2500 taz1700_ensembles.csv \u2502 \u251c\u2500\u2500 modes.in \u2502 \u251c\u2500\u2500 tvehicles.in \u2502 | \u2502 \u2514\u2500\u2500 Inputs/ \u2502 \u251c\u2500\u2500 taz1700_demographics_*.csv \u2502 \u251c\u2500\u2500 taz1700_geographics_*.csv \u2502 \u251c\u2500\u2500 taz1700_dummies.csv \u2502 \u251c\u2500\u2500 taz1700_pnr.csv \u2502 \u251c\u2500\u2500 time_slicing.csv \u2502 \u251c\u2500\u2500 time_slicing_gb.csv \u2502 \u251c\u2500\u2500 transit_adj.csv | \u2514\u2500\u2500 TruckBatchFiles/ \u2502 \u251c\u2500\u2500 *AsiaPacificv1.txt \u2502 \u251c\u2500\u2500 *CrossBorderv1.txt \u2502 \u251c\u2500\u2500 IRBatchIn.txt \u2502 \u251c\u2500\u2500 PMVActivity.txt | \u2514\u2500\u2500 RGBatchIn.txt \u2514\u2500\u2500 ...","title":"Base Networks Folder"},{"location":"workflow/#scripts-folder","text":"This folder contains python scripts used to run the model: Toolbox relocate tool: relocate_tools.bat , relocate_tools.sh , toolbox_modify.py Model Scripts toolbox: Phase3Scripts/ Analytics toolbox: Phase3Analytics/ Model utility toolbox: util/ Model tools, scripts and notebooks of model initialization and model runs: util/ RTM/ \u251c\u2500\u2500 Scripts/ \u2502 \u251c\u2500\u2500 relocate_tools.bat \u2502 \u251c\u2500\u2500 relocate_tools.sh \u2502 \u251c\u2500\u2500 toolbox_modify.py \u2502 | \u2502 \u251c\u2500\u2500 Phase3Scripts/ \u2502 \u251c\u2500\u2500 Phase3Analytics/ \u2502 \u251c\u2500\u2500 util/ \u2502 \u2514\u2500\u2500 Tools/ \u2514\u2500\u2500 ... Note The Scripts control the model behavior of the RTM. You are free to go through the script to familiarize with the implementation of the model. For more information regarding the modeling structure of the RTM, modeling decisions, data sources, estimation of sub models, please contact us .","title":"Scripts Folder"},{"location":"workflow/#other-folders","text":"Media folder Contains shapefiles, ArcGIS maps. Output data are typically stored here. Documentation folder contains printable user manuals. Logbook folder contains EMME logbook information generated by EMME Modeler tools. Template folder provides an empty databank that allow Modeler to initialize new RTM databanks. View folder contains standard views provided in the EMME environment. Worksheets folder contains standardized worksheets in the EMME environment. RTM/ \u251c\u2500\u2500 Media/ \u251c\u2500\u2500 Documentation/ \u251c\u2500\u2500 Logbook/ \u251c\u2500\u2500 Template/ \u251c\u2500\u2500 Views/ \u251c\u2500\u2500 Worksheets/ \u2514\u2500\u2500 ...","title":"Other Folders"},{"location":"workflow/#initialize-databank","text":"You can initialize a single databank using the EMME Modeler or initialize multiple databanks using EMME Notebook, depending on your need. To start the EMME, open the file. This will launch EMME, open the Minimal Base Databank's Placeholder Scenario when prompted.","title":"Initialize Databank"},{"location":"workflow/#with-emme-modeler","text":"To open Modeler, click on the EMME Modeler icon . Once the Modeler opens, find Translink RTM Phase 3 Model toolbox and open the Initialize Emmebank tool: Enter a folder name and a name for the databank. Try to be descriptive. For example, if this is a databank for editing or debugging network only, name it network_edit_something , if this is a final copy of a new business as usual run for year 2050, name it 00_BAU_2050 . Once you enter the names, click > Run . Once the run is completed, the Tool complete message will appear.","title":"With EMME Modeler"},{"location":"workflow/#with-emme-notebook","text":"If you are comfortable with python and Jupyter Notebook, we strongly recommend that you use EMME Notebook to initialize databanks. This improves the reproducibility of your model run. This is generally not needed for network scenario or testing, but for final copy of a run, it is highly recommend. To open EMME Notebook, click on the EMME Notebook icon . The EMME Notebook should open in your browser, if it didn't open automatically, look for http://localhost:xxxx/ in the EMME - Notebook command prompt window. The default is usually http://localhost:8888/ . Once opened, you should see a list of folders in the Scripts/ folder. Go to Tools/ folder and make a duplicate of init_many.ipynb , name it to something more descriptive for your use, like init_many_00_BAU_2050.ipynb , then open it. Modify params as needed, run the entire script to initialize the databank.","title":"With EMME Notebook"},{"location":"workflow/#build-scenario","text":"There are a wide range of changes you can make to the EMME base model for your study. We won't be able to cover them all in detail here, but here are some examples of model changes: demographics new roads or bridges new transit lines new transit stops transit fare tolls mobility pricing park and ride pricing etc...","title":"Build Scenario"},{"location":"workflow/#network-editing","text":"The EMME Network Editor provides users the ability to create and modify nodes, links, turns, transit lines, and transit segments. We will use a BRT line example to illustrate how to add modes and vehicles for the RTM, and edit networks in EMME.","title":"Network editing"},{"location":"workflow/#custom-inputs","text":"There are a number of custom inputs that the RTM uses at model initialization and run time to modify model behavior: At initiation Transit vehicles and modes At runtime Required files with model data demographic and geographic Optional files to manipulate model data Scalars: custom_scalars.csv Network: custom_network.txt Transit Lines: custom_tline.txt Transit Segment: custom_tseg.txt The optional custom_<datatype> series files can be placed in the RTM/<your run directory>/inputs folder of the RTM instance. These files are imported after the main model setup ( create scenarios and data import ) and can be used to change any model setting held in a scalar matrix or execute an arbitrary set of network link, transit line, or transit segment calculations. Files with a .csv extension indicate comma delimited data while files with a .txt extension indicate tab delimited data. Warning Do not leave a trailing new line or carriage return at the end of the files custom_<datatype>.txt files. In addition, there can be only one file of each name in the inputs folder.","title":"Custom Inputs"},{"location":"workflow/#custom-scalars","text":"This file allow the user to change data held in scalar matrices in the scripting without changing the scripting. This in turn allows the user to run multiple runs with the same scripts and different scalar matrix data. The custom_scalars.csv file has headers and requires the following information in comma delimited format. Matrix ID Matrix Name Matrix Description Value The EMME Matrix ID number The EMME Matrix Name The EMME Matrix Description The value to change Below is an example of changing the auto operating cost using the custom scalars file.","title":"Custom Scalars"},{"location":"workflow/#custom-network","text":"This file allows the user to execute an arbitrary set of network link calculations prior to running the model. The custom_network.txt file should not have headers and requires the following information in tab delimited format Period Result Expression Selection Aggregation AM, MD, PM, or ALL Where the calculation should be stored (for instance @capacity) The network calculation to be executed Which link(s) to execute the calculation on (optional - can be left blank to update all links) Results aggregation (optional and generally left blank) Below is an example of removing one lane and reducing capacity on links 111902-111904 and 111904-111902, and setting the signal delay to 0 for all links that are not VDF 14 for all three assignment periods. Note that there is no carriage return on the last line.","title":"Custom Network"},{"location":"workflow/#custom-transit-lines","text":"This file allows the user to execute an arbitrary set of network transit line calculations prior to running the model. The custom_tline.txt file should not have headers and requires the following information in tab delimited format Period Result Expression Selection Aggregation AM, MD, PM, or ALL Where the calculation should be stored (for instance hdw) The network calculation to be executed Which line(s) to execute the calculation on (optional - can be left blank to update all lines) Results aggregation (optional and generally left blank) Below is an example of reducing the headway on all lines except those in the Fraser Valley during the AM and PM peak hours, and setting the signal delay to 0 for all links that are not VDF 14 for all three assignment periods. Note that there is no carriage return on the last line.","title":"Custom Transit Lines"},{"location":"workflow/#custom-transit-segments","text":"This file allows the user to execute an arbitrary set of network transit segment calculations prior to running the model. The custom_tseg.txt file should not have headers and requires the following information in tab delimited format Period Result Expression Selection Aggregation AM, MD, PM, or ALL Where the calculation should be stored (for instance ttf) The network calculation to be executed Which line(s) to execute the calculation on (optional - can be left blank to update all lines) Results aggregation (optional and generally left blank) Below is an example of changing the transit time function (ttf) on links 111902-111904 and 111904-111902 to ttf2. Note that there is no carriage return on the last line.","title":"Custom Transit Segments"},{"location":"workflow/#example-2050-brt-line","text":"Similar to most model application exercises, in our example, there are two main components of changes we are making to the 2050 base model: network editing and model custom inputs. Network editing - adding a new transit line Custom inputs Add congestion pricing to the network with custom_network.txt input file Use a custom demographic file for corridor intensification","title":"Example: 2050 BRT Line"},{"location":"workflow/#step-1-create-new-scenarios","text":"Duplicate the base scenario input files, and rename them with a new scenario number. For example, if you are making changes on top of scenario \"5000\", name it \"5001\", \"5002\". Once you added all the scenarios, add these new scenario numbers into the InitEmmebank.py script. This will allow the initialize emmebank modeler tool to load the new scenarios.","title":"Step 1: create new scenarios"},{"location":"workflow/#step-2-add-new-modes","text":"Before we create a new transit line, we need to make sure the mode and the vehicle of is available, add the new mode to modes.in file in the base network folder: Then check the tvehicles.in file in the base network folder: Note After the modes are added, it won't be available in the already initialized databank and scenario. You should re-initialize a working copy of the databank. Now, you will need to initialize a new databank with the new scenario number, mode, and vehicle. You can give it a descriptive and abbreviated name such as 01_Lg_BRT_CP_LU_2050 .","title":"Step 2: add new modes"},{"location":"workflow/#step-3-perform-network-editing","text":"Open EMME network editor , add notes, links, and transit line as needed. Make sure you save a copy of the build file before you save and exit the scenario. Build files can be created from any changes you made while in the Network Editor. The build file is a great way to save and replicate model network changes. If you have a build file, you can stage it and run the changes. * Copy your build file to Network_builds/ folder. * Open \"Network History and Builds\" prompt from EMME Network Editor . Click the folder icon to \"Add network builds\", then click \"Stage\". * Preview the build, then run the build:","title":"Step 3: perform network editing"},{"location":"workflow/#step-4-set-up-custom-inputs","text":"For the BRT example, we will use custom_network.txt and a simple 8-zone shapefile to add congestion pricing attribute to the network in batch. We will also load a custom demographic file with 20% population intensification along the study corridor. The custom input file such as custom_network.txt needs to be placed in the Input/ folder within the emme databank folder, such as the folder db_01_Lg_BRT_CP_LU_2050 or 01_Lg_BRT_CP_LU_2050 . (Do not place the file in the BaseNetworks folder!) The custom demographic file such as taz1700_demographics_2050-20.csv needs to be selected as the demographic input when running the model.","title":"Step 4: set up custom inputs"},{"location":"workflow/#export-scenario","text":"While in most cases your current databank for the alternative scenario is ready to run, it is important to export your new scenario network and organize all input files into a sub folder within the Scenario_Inputs folder. This allows you to share your new scenario with other users without needing to copy the entire databank with results. This also allow you to quickly reinitialize the scenario to run on a newer version of the RTM.","title":"Export Scenario"},{"location":"workflow/#export-network","text":"To export your scenario's network, open EMME Modeler: Then select your new scenario to export:","title":"Export Network"},{"location":"workflow/#organize-scenario-inputs","text":"We highly recommend that you store every input required to rebuild your new scenario and replicate your model run within a sub folder of the Scenario_Inputs folder. For our example, this would be the folder structure for all the changes we have made in our BRT example: RTM/ \u251c\u2500\u2500 Scenario_Inputs/ \u2502 \u2514\u2500\u2500 01_2050-20-hw8-cp_Lg_BRT-g/ \u2502 \u251c\u2500\u2500 custom_network.txt \u2502 \u251c\u2500\u2500 modes.in \u2502 \u251c\u2500\u2500 tvehicles.in \u2502 \u2502 \u2502 \u251c\u2500\u2500 BaseNetworks/ \u2502 \u2502 \u251c\u2500\u2500 Inputs/ \u2502 \u2502 \u2502 \u2514\u2500\u2500 taz1700_demographics_2050-20.csv \u2502 \u2502 \u251c\u2500\u2500 base_network_5001.txt \u2502 \u2502 \u2514\u2500\u2500 ... \u2502 \u251c\u2500\u2500 Scripts/Phase3Scripts/ \u2502 \u2502 \u251c\u2500\u2500 Tools/ \u2502 \u2502 \u2502 \u2502\u2500\u2500 init_many_example_lgrt.ipynb \u2502 \u2502 \u2502 \u2514\u2500\u2500 run_many_example_lgrt.ipynb \u2502 \u2502 \u2514\u2500\u2500 Phase3Scripts/ \u2502 \u2502 \u2514\u2500\u2500 InitEmmebank.py \u2502 \u2514\u2500\u2500 Media/ \u2502 \u2514\u2500\u2500 RTM_8ZonePolygon.shp \u2514\u2500\u2500 ...","title":"Organize Scenario Inputs"},{"location":"workflow/#run-model","text":"You can run the model using a single databank using the EMME Modeler or run multiple databanks using the EMME Notebook, depending on your need.","title":"Run Model"},{"location":"workflow/#emme-modeler","text":"Once you have set up all the input files in the databank, such as customized demographics, custom input files, etc, you are ready to do a full model run using the EMME Modeler. To open Modeler, click on the EMME Modeler icon . Find Translink RTM Phase 3 Model toolbox and open the Run RTM3 tool: Change the Full Model Run settings as needed. Make sure to enter the correct model horizon year, scenario, demographic and geographic inputs. Click Run . Each model run can take 2 to 4 hours depending on the custom settings and scenario. Warning Do not interrupt the model run. The RTM model is not designed to be run in separate stages or run multiple times. If you stopped a model run before it is done, you should start over - reinitialize the databank and start run.","title":"EMME Modeler"},{"location":"workflow/#emme-notebook","text":"The EMME Notebook allows you to create .ipynb scripts that handles multiple model runs and runs with complex set up. It is ideal for our BRT example where we needed to perform link tagging and use custom network input file for congestion pricing. To open EMME Notebook, click on the EMME Notebook icon . The EMME Notebook should open in your browser, if it didn't open automatically, look for http://localhost:xxxx/ in the EMME - Notebook command prompt window. The default is usually http://localhost:8888/ . Once opened, you should see a list of folders in the Scripts/ folder. Go to Tools/ folder and make a duplicate of run_many.ipynb , name it to something more descriptive for your use, like run_many_00_BAU_2050.ipynb or run_many_example_lgrt.ipynb , then open it. Modify params as needed. Make sure you carefully review the script associated with the model run. You may need to add new code to this section depending on the requirements of your model run. Run the entire script to perform the full model run with custom settings.","title":"EMME Notebook"},{"location":"workflow/#commit-changes","text":"If this is your first time using git after an installation, see Git Setup . While working with the RTM on git, here are some ground rules: Main project branches ( master , example_brt_proj ) are always protected. Push a temp branch then do pull request to merge your changes Only stage and commit model inputs and settings, never databanks Any scenario-specific changes for scripts should be placed into Scenario_Inputs for commit Organize a Scenario_Inputs folder when you finish a scenario Use active verb for commit messages, like \"add scenario inputs for brt examples.\" Warning Do not commit the databank associated with the model run. We recommend you to place the databank folders in your version of the .gitignore . When staging and committing model changes, think about what other users or developers may need to run your scenario from scratch. Commit inputs and set up, not the results.","title":"Commit Changes"},{"location":"workflow/#push-changes-to-github","text":"If you are a collaborator, you may push your changes to the rtm repository on GitHub. You will not be able to push directly to most of the branches already on the rtm repository as they are protected, so always push your working branch and merge to any main branch with a pull request. An admin will review your changes when you submit a pull request. git push origin master_your-project Learn more about git and read more about GitHub pull request .","title":"Push Changes to GitHub"},{"location":"about/contributing/","text":"Contributing \u00b6 If you require access to the RTM or would like to stay in touch, please join our mailing list. Name (required) Organization (required) Email (required) Phone Number Comments Thank you for joining our mailing list. If you have trouble with submitting the form, please visit Google Forms .","title":"Contributing"},{"location":"about/contributing/#contributing","text":"If you require access to the RTM or would like to stay in touch, please join our mailing list. Name (required) Organization (required) Email (required) Phone Number Comments Thank you for joining our mailing list. If you have trouble with submitting the form, please visit Google Forms .","title":"Contributing"},{"location":"about/license/","text":"License \u00b6","title":"License"},{"location":"about/license/#license","text":"","title":"License"},{"location":"about/release-notes/","text":"Release Notes \u00b6","title":"Release Notes"},{"location":"about/release-notes/#release-notes","text":"","title":"Release Notes"}]}